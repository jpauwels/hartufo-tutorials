{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from math import floor\n",
    "import numpy as np\n",
    "from hartufo import CipicPlane, AriPlane, ListenPlane, CrossModPlane, BiLiPlane, ItaPlane, HutubsPlane, RiecPlane, Sadie2Plane, Princeton3D3APlane, ChedarPlane, WidespreadPlane, ScutPlane, SonicomPlane\n",
    "from hartufo import HrirSpec\n",
    "from hartufo.full import split_by_angles\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by Andreopoulou and Roginska's paper \"Towards the Creation of a Standardized HRTF Repository\", presented at the 131st convention of the AES (2011)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path('../hartufo-collections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_collections = (\n",
    "    # (CipicPlane, base_dir / 'CIPIC'),\n",
    "    (ListenPlane, base_dir / 'Ircam Listen'),\n",
    "    (CrossModPlane, base_dir / 'Ircam CrossMod'),\n",
    "    # (BiLiPlane, base_dir / 'Ircam BiLi'),\n",
    "    (AriPlane, base_dir / 'ARI'),\n",
    "    (RiecPlane, base_dir / 'RIEC'),\n",
    "    (ItaPlane, base_dir / 'ITA'),\n",
    "    # (Princeton3D3APlane, base_dir / '3D3A'),\n",
    "    # (Sadie2Plane, base_dir / 'SADIE II'),\n",
    "    (ScutPlane, base_dir / 'SCUT'),\n",
    "    (HutubsPlane, base_dir / 'HUTUBS'),\n",
    "    # (ChedarPlane, base_dir / 'CHEDAR'),\n",
    "    # (WidespreadPlane, base_dir / 'Widespread'),\n",
    "    # (SonicomPlane, base_dir / 'SONICOM'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane = 'horizontal'\n",
    "domain = 'magnitude_db'\n",
    "side = 'both-left'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine common ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get positions, samplerates and lengths for all datasets\n",
    "plane_angles = []\n",
    "samplerates = []\n",
    "hrir_lengths = []\n",
    "for collection, data_dir in plane_collections:\n",
    "    plane_offset = -0.72 if collection == ItaPlane and plane == 'horizontal' else 0\n",
    "    ds = collection(data_dir, plane, domain='time', side='left', subject_ids='first', plane_offset=plane_offset, verify=False)\n",
    "    plane_angles.append(set(ds.plane_angles))\n",
    "    samplerates.append(ds.hrir_samplerate)\n",
    "    hrir_lengths.append(ds.hrir_length)\n",
    "# Determine common angles and minimum samplerate and length\n",
    "common_plane_angles = sorted(set.intersection(*plane_angles))\n",
    "samplerate = min(samplerates)\n",
    "hrir_length = min([floor(samplerate / sr * l) for sr, l in zip(samplerates, hrir_lengths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_plane_angles, samplerate, hrir_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read complete collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all datapoints with common parameters\n",
    "datasets = []\n",
    "for collection, data_dir in plane_collections:\n",
    "    print(data_dir)\n",
    "    plane_offset = -0.72 if collection == ItaPlane and plane == 'horizontal' else 0\n",
    "    exclude_ids = (1, 2) if collection == Sadie2Plane else None\n",
    "    ds = collection(\n",
    "        data_dir, plane, domain, side, plane_angles=common_plane_angles,\n",
    "        plane_offset=plane_offset, hrir_samplerate=samplerate, hrir_length=hrir_length, hrir_min_phase=True, exclude_ids=exclude_ids, verify=False,\n",
    "    )\n",
    "    datasets.append(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select balanced subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_measurements = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_collection_size = min(len(d) for d in datasets)\n",
    "# max_collection_size = 999\n",
    "if individual_measurements: # each datapoint is a single measurement location (HRIR)\n",
    "    hrtf_size = datasets[0][0]['features'].shape[-1]\n",
    "    balanced_features = [np.array([angle_ds[:max_collection_size]['features'] for angle_ds in split_by_angles(ds)]).reshape(-1, hrtf_size) for ds in datasets]\n",
    "else: # each datapoint is all (retained) measurement locations (HRIRs) for a subject/side combination\n",
    "    balanced_features = [np.array([ex.reshape(-1) for ex in ds[:max_collection_size]['features']]) for ds in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(balanced_features), balanced_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard scaling per collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [np.mean(f, axis=0) for f in balanced_features]\n",
    "stdevs = [np.std(f, axis=0) for f in balanced_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(means), means[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_features = [(f - mean) / stdev for f, mean, stdev in zip(balanced_features, means, stdevs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalised_features), normalised_features[0].shape, normalised_features[5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance between datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prenorm_distances = pairwise_distances(np.row_stack(balanced_features), metric='euclidean')\n",
    "postnorm_distances = pairwise_distances(np.row_stack(normalised_features), metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(prenorm_distances)\n",
    "plt.matshow(postnorm_distances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6da6f4d86ef4f519a6c275da41ee9fe88a8dc4690964d65fd688f7f44823bf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
